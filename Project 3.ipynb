{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data 620 | Project 3\n",
    "\n",
    "#### Team 3: Scott Karr, Omar Pineda Jr., Vikas Sinha, Aryeh Sturm, Antonio Bayquen\n",
    "\n",
    "https://www.nltk.org/book/ch06.html\n",
    "\n",
    "#### This work is a recitation of the gender classification exercise in Chapter 6 of Natural Language Processing with Python along with revisions to the gender features extractor which improve performance on the test set to 82.4%.\n",
    "\n",
    "\n",
    "# Requirements:\n",
    "Project 3 - This is a Team Project!\n",
    "<center>------------------------------------------------------------------------------------------- o ----------------------------------------------------------------------------------------</center>\n",
    "For this project, please work with the entire class as one collaborative group! Your project should be submitted (as a Jupyter Notebook via GitHub) by end of the due date. The group should present their code and findings in our meetup.\n",
    "\n",
    "The ability to be an effective member of a virtual team is highly valued in the data science job market.\n",
    "<center>------------------------------------------------------------------------------------------- o ----------------------------------------------------------------------------------------</center>\n",
    "\n",
    "\n",
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can.\n",
    "\n",
    "Begin by splitting the Names Corpus into three subsets: \n",
    "\n",
    "        (1) 500 words for the test set\n",
    "        (2) 500 words for the dev- test set, and \n",
    "        (3) the remaining 6900 words for the training set \n",
    "        \n",
    "Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set.\n",
    "\n",
    "How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?\n",
    "Source: Natural Language Processing with Python, exercise 6.10.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>6. Learning to Classify Text</center>\n",
    "\n",
    "Detecting patterns is a central part of Natural Language Processing. Words ending in \"-ed\" tend to be past tense verbs (5.). Frequent use of \"will\" is indicative of news text (3). These observable patterns — word structure and word frequency — happen to correlate with particular aspects of meaning, such as tense and topic. But how did we know where to start looking, which aspects of form to associate with which aspects of meaning?\n",
    "\n",
    "The goal of this chapter is to answer the following questions:\n",
    "\n",
    "    (1) How can we identify particular features of language data that are salient for classifying it?\n",
    "    (2) How can we construct models of language that can perform language processing tasks automatically?\n",
    "    (3) What can we learn about language from these models?\n",
    "\n",
    "Along the way we will study some important machine learning techniques, including decision trees, naive Bayes' classifiers, and maximum entropy classifiers. We will gloss over the mathematical and statistical underpinnings of these techniques, focusing instead on how and when to use them (see the Further Readings section for more technical background). Before looking at these methods, we first need to appreciate the broad scope of this topic.\n",
    "\n",
    "# 1   Supervised Classification\n",
    "Classification is the task of choosing the correct class label for a given input. In basic classification tasks, each input is considered in isolation from all other inputs, and the set of labels is defined in advance. Some examples of classification tasks are:\n",
    "\n",
    "Deciding whether an email is spam or not.\n",
    "Deciding what the topic of a news article is, from a fixed list of topic areas such as \"sports,\" \"technology,\" and \"politics.\"\n",
    "Deciding whether a given occurrence of the word bank is used to refer to a river bank, a financial institution, the act of tilting to the side, or the act of depositing something in a financial institution.\n",
    "The basic classification task has a number of interesting variants. For example, in multi-class classification, each instance may be assigned multiple labels; in open-class classification, the set of labels is not defined in advance; and in sequence classification, a list of inputs are jointly classified.\n",
    "\n",
    "A classifier is called supervised if it is built based on training corpora containing the correct label for each input. The framework used by supervised classification is shown in 1.1.\n",
    "\n",
    "![supervised-classification.png](https://raw.githubusercontent.com/vsinha-cuny/data620Proj3/master/supervised-classification.png)\n",
    "\n",
    "Figure 1.1: Supervised Classification. \n",
    "\n",
    "    (a) During training, a feature extractor is used to convert each input value to a feature set. These \n",
    "        feature sets, which capture the basic information about each input that should be used to classify it,  \n",
    "        are discussed in the next section. Pairs of feature sets and labels are fed into the machine learning        \n",
    "        algorithm to generate a model. \n",
    "\n",
    "    (b) During prediction, the same feature extractor is used to convert unseen inputs to feature sets. These \n",
    "        feature sets are then fed into the model, which generates predicted labels.\n",
    "\n",
    "In the rest of this section, we will look at how classifiers can be employed to solve a wide variety of tasks. Our discussion is not intended to be comprehensive, but to give a representative sample of tasks that can be performed with the help of text classifiers.\n",
    "\n",
    "# 1.1   Gender Identification\n",
    "\n",
    "Male and female names have some distinctive characteristics. Names ending in a, e and i are likely to be female, while names ending in k, o, r, s and t are likely to be male. Let's build a classifier to model these differences more precisely.\n",
    "\n",
    "The first step in creating a classifier is deciding what features of the input are relevant, and how to encode those features. For this example, we'll start by just looking at the final letter of a given name. The following feature extractor function builds a dictionary containing relevant information about a given name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "#nltk.download('names')\n",
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(name):\n",
    "    name=name.upper()\n",
    "    return {\n",
    "        'last_letter': name[-1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'K'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features('Shrek')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined a feature extractor, we need to prepare a list of examples and corresponding class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7944\n"
     ]
    }
   ],
   "source": [
    "# get list of ordered names from nltk.corpus by importing names\n",
    "labeled_names = (\n",
    "                    [(name, 'male') for name in names.words('male.txt')] +\n",
    "                    [(name, 'female') for name in names.words('female.txt')]\n",
    ")\n",
    "\n",
    "np.random.seed(222)\n",
    "# randomized the name orders\n",
    "random.shuffle(labeled_names)\n",
    "print(len(labeled_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the feature extractor to process the names data, and divide the resulting list of feature sets into a training set and a test set. The training set is used to train a new \"naive Bayes\" classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(222)\n",
    "\n",
    "# featuresets, train_set & test_set are dictionaries containing 2 elements per record, \n",
    "#  - the gender function return value &\n",
    "#  - the actual gender from the labeled_names set that was imported\n",
    "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "\n",
    "#  apply Naive Bayes guess to train set and check classifier's predictions\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will learn more about the naive Bayes classifier later in the chapter. For now, let's just test it out on some names that did not appear in its training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo is: male\n",
      "Trinity is: female\n"
     ]
    }
   ],
   "source": [
    "# use trained classifier to predict 2 names gender based upon last character\n",
    "print('Neo is: ' + classifier.classify(gender_features('Neo')))\n",
    "print('Trinity is: ' + classifier.classify(gender_features('Trinity')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that these character names from The Matrix are correctly classified. Although this science fiction movie is set in 2199, it still conforms with our expectations about names and genders. We can systematically evaluate the classifier on a much larger quantity of unseen data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can examine the classifier to determine which features it found most effective for distinguishing the names' genders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'A'            female : male   =     37.2 : 1.0\n",
      "             last_letter = 'K'              male : female =     30.5 : 1.0\n",
      "             last_letter = 'P'              male : female =     18.5 : 1.0\n",
      "             last_letter = 'F'              male : female =     14.4 : 1.0\n",
      "             last_letter = 'V'              male : female =     11.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This listing shows that the names in the training set that end in \"a\" are female 33 times more often than they are male, but names that end in \"k\" are male 32 times more often than they are female. These ratios are known as likelihood ratios, and can be useful for comparing different feature-outcome relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with large corpora, constructing a single list that contains the features of every instance can use up a large amount of memory. In these cases, use the function nltk.classify.apply_features, which returns an object that acts like a list but does not store all the feature sets in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import apply_features\n",
    "train_set = apply_features(gender_features, labeled_names[500:])\n",
    "test_set = apply_features(gender_features, labeled_names[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, feature extractors are built through a process of trial-and-error, guided by intuitions about what information is relevant to the problem. It's common to start with a \"kitchen sink\" approach, including all the features that you can think of, and then checking to see which features actually are helpful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[:1].lower()\n",
    "    features[\"first_two\"] = name[:2].lower()   \n",
    "    features[\"first_three\"] = name[:3].lower()      \n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    features[\"last_two\"] = name[-2:].lower()     \n",
    "    features[\"suffix3\"] = name[-3:].lower()\n",
    "    features[\"suffix4\"] = name[-4:].lower()    \n",
    "    features[\"last_is_vowel\"] = (name[-1].lower() in 'aeiouy')\n",
    "    features[\"odd\"] = (name.find(\"-\") > 0),     \n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featuresets, train_set & test_set are dictionaries containing 2 elements per record, \n",
    "#  - the gender function return value &\n",
    "#  - the actual gender from the labeled_names set that was imported\n",
    "featuresets = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "\n",
    "#  apply Naive Bayes guess to train set and check classifier's predictions\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                last_two = 'na'           female : male   =     99.7 : 1.0\n",
      "                last_two = 'la'           female : male   =     78.1 : 1.0\n",
      "                last_two = 'us'             male : female =     40.6 : 1.0\n",
      "                last_two = 'ia'           female : male   =     40.6 : 1.0\n",
      "             last_letter = 'a'            female : male   =     37.2 : 1.0\n",
      "             last_letter = 'k'              male : female =     30.5 : 1.0\n",
      "                last_two = 'do'             male : female =     27.0 : 1.0\n",
      "                last_two = 'ra'           female : male   =     26.7 : 1.0\n",
      "                 suffix3 = 'ana'          female : male   =     26.5 : 1.0\n",
      "                 suffix4 = 'bert'           male : female =     26.1 : 1.0\n",
      "                last_two = 'rd'             male : female =     25.5 : 1.0\n",
      "                last_two = 'ta'           female : male   =     25.2 : 1.0\n",
      "                last_two = 'io'             male : female =     24.8 : 1.0\n",
      "                last_two = 'ch'             male : female =     24.8 : 1.0\n",
      "                 suffix3 = 'tta'          female : male   =     24.3 : 1.0\n",
      "                 suffix4 = 'anne'         female : male   =     24.1 : 1.0\n",
      "                last_two = 'rt'             male : female =     23.8 : 1.0\n",
      "                last_two = 'ld'             male : female =     22.1 : 1.0\n",
      "                 suffix4 = 'etta'         female : male   =     21.8 : 1.0\n",
      "                 suffix3 = 'ard'            male : female =     21.4 : 1.0\n",
      "                 suffix3 = 'nne'          female : male   =     20.8 : 1.0\n",
      "             last_letter = 'p'              male : female =     18.5 : 1.0\n",
      "                last_two = 'os'             male : female =     17.1 : 1.0\n",
      "                 suffix3 = 'old'            male : female =     17.0 : 1.0\n",
      "                 suffix3 = 'ita'          female : male   =     16.4 : 1.0\n",
      "               first_two = 'hu'             male : female =     16.0 : 1.0\n",
      "                 suffix3 = 'ela'          female : male   =     15.3 : 1.0\n",
      "                 suffix3 = 'dra'          female : male   =     14.9 : 1.0\n",
      "             last_letter = 'f'              male : female =     14.4 : 1.0\n",
      "                last_two = 'ka'           female : male   =     14.3 : 1.0\n",
      "                 suffix3 = 'ria'          female : male   =     13.6 : 1.0\n",
      "                 suffix3 = 'ert'            male : female =     13.0 : 1.0\n",
      "             first_three = 'tha'            male : female =     12.9 : 1.0\n",
      "               first_two = 'ya'             male : female =     12.7 : 1.0\n",
      "                 suffix3 = 'son'            male : female =     12.5 : 1.0\n",
      "                 suffix4 = 'ndra'         female : male   =     12.0 : 1.0\n",
      "             first_three = 'cat'          female : male   =     11.8 : 1.0\n",
      "                last_two = 'rn'             male : female =     11.6 : 1.0\n",
      "                 suffix3 = 'vin'            male : female =     11.4 : 1.0\n",
      "                last_two = 'ya'           female : male   =     11.1 : 1.0\n",
      "                last_two = 'ti'           female : male   =     11.1 : 1.0\n",
      "             last_letter = 'v'              male : female =     11.1 : 1.0\n",
      "                 suffix3 = 'nni'          female : male   =     11.0 : 1.0\n",
      "             first_three = 'dor'          female : male   =     10.7 : 1.0\n",
      "               first_two = 'tu'             male : female =     10.5 : 1.0\n",
      "                last_two = 'ns'             male : female =     10.5 : 1.0\n",
      "                 suffix3 = 'tha'          female : male   =     10.1 : 1.0\n",
      "               first_two = 'wa'             male : female =      9.8 : 1.0\n",
      "                 suffix3 = 'ias'            male : female =      9.8 : 1.0\n",
      "             last_letter = 'd'              male : female =      9.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for the Isabelle as an example\n",
    "# gender_features2('Isabelle') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there are usually limits to the number of features that you should use with a given learning algorithm — if you provide too many features, then the algorithm will have a higher chance of relying on idiosyncrasies of your training data that don't generalize well to new examples. This problem is known as overfitting, and can be especially problematic when working with small training sets. For example, if we train a naive Bayes classifier using the feature extractor shown in 1.2, it will overfit the relatively small training set, resulting in a system whose accuracy is about 1% lower than the accuracy of a classifier that only pays attention to the final letter of each name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(224)\n",
    "\n",
    "featuresets = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once an initial set of features has been chosen, a very productive method for refining the feature set is error analysis. First, we select a development set, containing the corpus data for creating the model. This development set is then subdivided into the training set and the dev-test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = labeled_names[1500:]\n",
    "devtest_names = labeled_names[500:1500]\n",
    "test_names = labeled_names[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set is used to train the model, and the dev-test set is used to perform error analysis. The test set serves in our final evaluation of the system. For reasons discussed below, it is important that we employ a separate dev-test set for error analysis, rather than just using the test set. The division of the corpus data into different subsets is shown in 1.3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![corpus-org.png](https://raw.githubusercontent.com/vsinha-cuny/data620Proj3/master/corpus-org.png)\n",
    "\n",
    "Figure 1.3: Organization of corpus data for training supervised classifiers. The corpus data is divided into two sets: the development set, and the test set. The development set is often further subdivided into a training set and a dev-test set.\n",
    "\n",
    "Having divided the corpus into appropriate datasets, we train a model using the training set [1], and then run it on the dev-test set [2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.831\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(225)\n",
    "train_set = [(gender_features2(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(gender_features2(n), gender) for (n, gender) in devtest_names]\n",
    "test_set = [(gender_features2(n), gender) for (n, gender) in test_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set) # [1]\n",
    "print(nltk.classify.accuracy(classifier, devtest_set)) # [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also considered using a Decision Tree classifier, but proceeded with the Naive Bayes classifier instead due to its greater accuracy.\n",
    "\n",
    "![decision-tree.png](https://raw.githubusercontent.com/vsinha-cuny/data620Proj3/master/decision-tree.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.689\n"
     ]
    }
   ],
   "source": [
    "classifier2 = nltk.DecisionTreeClassifier.train(train_set)\n",
    "print(f'Decision Tree Accuracy: {nltk.classify.accuracy(classifier2, devtest_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.373\n",
      "             2          -0.58801        0.627\n",
      "             3          -0.55283        0.634\n",
      "             4          -0.52182        0.697\n",
      "             5          -0.49454        0.763\n",
      "             6          -0.47054        0.801\n",
      "             7          -0.44937        0.826\n",
      "             8          -0.43063        0.843\n",
      "             9          -0.41396        0.854\n",
      "            10          -0.39907        0.861\n",
      "            11          -0.38570        0.867\n",
      "            12          -0.37364        0.873\n",
      "            13          -0.36271        0.877\n",
      "            14          -0.35275        0.881\n",
      "            15          -0.34365        0.883\n",
      "            16          -0.33530        0.886\n",
      "            17          -0.32760        0.889\n",
      "            18          -0.32048        0.891\n",
      "            19          -0.31388        0.893\n",
      "            20          -0.30773        0.896\n",
      "            21          -0.30199        0.898\n",
      "            22          -0.29661        0.898\n",
      "            23          -0.29156        0.899\n",
      "            24          -0.28681        0.901\n",
      "            25          -0.28233        0.901\n",
      "            26          -0.27810        0.902\n",
      "            27          -0.27408        0.903\n",
      "            28          -0.27028        0.903\n",
      "            29          -0.26666        0.904\n",
      "            30          -0.26321        0.905\n",
      "            31          -0.25992        0.907\n",
      "            32          -0.25677        0.908\n",
      "            33          -0.25376        0.909\n",
      "            34          -0.25088        0.909\n",
      "            35          -0.24812        0.911\n",
      "            36          -0.24546        0.911\n",
      "            37          -0.24291        0.912\n",
      "            38          -0.24045        0.913\n",
      "            39          -0.23807        0.914\n",
      "            40          -0.23579        0.916\n",
      "            41          -0.23358        0.916\n",
      "            42          -0.23144        0.917\n",
      "            43          -0.22938        0.917\n",
      "            44          -0.22738        0.918\n",
      "            45          -0.22544        0.918\n",
      "            46          -0.22356        0.919\n",
      "            47          -0.22174        0.919\n",
      "            48          -0.21997        0.919\n",
      "            49          -0.21825        0.920\n",
      "            50          -0.21658        0.921\n",
      "            51          -0.21495        0.921\n",
      "            52          -0.21337        0.922\n",
      "            53          -0.21182        0.922\n",
      "            54          -0.21032        0.924\n",
      "            55          -0.20886        0.924\n",
      "            56          -0.20743        0.924\n",
      "            57          -0.20603        0.925\n",
      "            58          -0.20467        0.925\n",
      "            59          -0.20334        0.926\n",
      "            60          -0.20204        0.927\n",
      "            61          -0.20077        0.927\n",
      "            62          -0.19953        0.927\n",
      "            63          -0.19831        0.928\n",
      "            64          -0.19712        0.928\n",
      "            65          -0.19596        0.928\n",
      "            66          -0.19482        0.928\n",
      "            67          -0.19370        0.929\n",
      "            68          -0.19260        0.929\n",
      "            69          -0.19153        0.930\n",
      "            70          -0.19048        0.930\n",
      "            71          -0.18945        0.930\n",
      "            72          -0.18843        0.930\n",
      "            73          -0.18744        0.930\n",
      "            74          -0.18647        0.930\n",
      "            75          -0.18551        0.930\n",
      "            76          -0.18457        0.930\n",
      "            77          -0.18364        0.931\n",
      "            78          -0.18274        0.932\n",
      "            79          -0.18185        0.932\n",
      "            80          -0.18097        0.932\n",
      "            81          -0.18011        0.932\n",
      "            82          -0.17926        0.933\n",
      "            83          -0.17843        0.933\n",
      "            84          -0.17761        0.933\n",
      "            85          -0.17680        0.934\n",
      "            86          -0.17601        0.934\n",
      "            87          -0.17523        0.934\n",
      "            88          -0.17446        0.934\n",
      "            89          -0.17370        0.935\n",
      "            90          -0.17295        0.935\n",
      "            91          -0.17222        0.935\n",
      "            92          -0.17150        0.935\n",
      "            93          -0.17078        0.935\n",
      "            94          -0.17008        0.935\n",
      "            95          -0.16939        0.936\n",
      "            96          -0.16871        0.936\n",
      "            97          -0.16803        0.936\n",
      "            98          -0.16737        0.936\n",
      "            99          -0.16672        0.936\n",
      "         Final          -0.16607        0.936\n",
      "Maximum entropy Accuracy: 0.837\n"
     ]
    }
   ],
   "source": [
    "classifier3 = nltk.MaxentClassifier.train(train_set)\n",
    "print(f'Maximum entropy Accuracy: {nltk.classify.accuracy(classifier3, devtest_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the dev-test set, we can generate a list of the errors that the classifier makes when predicting name genders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier.classify(gender_features2(name))\n",
    "    if guess != tag:\n",
    "        errors.append( (tag, guess, name)\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then examine individual error cases where the model predicted the wrong label, and try to determine what additional pieces of information would allow it to make the right decision (or which existing pieces of information are tricking it into making the wrong decision). The feature set can then be adjusted accordingly. The names classifier that we have built generates about 100 errors on the dev-test corpus:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female   guess=male     name=Angil                         \n",
      "correct=female   guess=male     name=Ariel                         \n",
      "correct=female   guess=male     name=Auguste                       \n",
      "correct=female   guess=male     name=Barry                         \n",
      "correct=female   guess=male     name=Beitris                       \n",
      "correct=female   guess=male     name=Bird                          \n",
      "correct=female   guess=male     name=Bren                          \n",
      "correct=female   guess=male     name=Bridgett                      \n",
      "correct=female   guess=male     name=Brook                         \n",
      "correct=female   guess=male     name=Brynn                         \n",
      "correct=female   guess=male     name=Buffy                         \n",
      "correct=female   guess=male     name=Calypso                       \n",
      "correct=female   guess=male     name=Camel                         \n",
      "correct=female   guess=male     name=Chad                          \n",
      "correct=female   guess=male     name=Charlott                      \n",
      "correct=female   guess=male     name=Charmain                      \n",
      "correct=female   guess=male     name=Charmion                      \n",
      "correct=female   guess=male     name=Chris                         \n",
      "correct=female   guess=male     name=Christen                      \n",
      "correct=female   guess=male     name=Christin                      \n",
      "correct=female   guess=male     name=Cody                          \n",
      "correct=female   guess=male     name=Conney                        \n",
      "correct=female   guess=male     name=Correy                        \n",
      "correct=female   guess=male     name=Cristin                       \n",
      "correct=female   guess=male     name=Dallas                        \n",
      "correct=female   guess=male     name=Darcy                         \n",
      "correct=female   guess=male     name=Dawn                          \n",
      "correct=female   guess=male     name=Deb                           \n",
      "correct=female   guess=male     name=Dell                          \n",
      "correct=female   guess=male     name=Dido                          \n",
      "correct=female   guess=male     name=Dionis                        \n",
      "correct=female   guess=male     name=Dorian                        \n",
      "correct=female   guess=male     name=Dot                           \n",
      "correct=female   guess=male     name=Dove                          \n",
      "correct=female   guess=male     name=Em                            \n",
      "correct=female   guess=male     name=Eran                          \n",
      "correct=female   guess=male     name=Fawn                          \n",
      "correct=female   guess=male     name=Freddy                        \n",
      "correct=female   guess=male     name=Garland                       \n",
      "correct=female   guess=male     name=Gen                           \n",
      "correct=female   guess=male     name=Gerry                         \n",
      "correct=female   guess=male     name=Gert                          \n",
      "correct=female   guess=male     name=Glad                          \n",
      "correct=female   guess=male     name=Gretal                        \n",
      "correct=female   guess=male     name=Gus                           \n",
      "correct=female   guess=male     name=Hannis                        \n",
      "correct=female   guess=male     name=Harmony                       \n",
      "correct=female   guess=male     name=Hildegaard                    \n",
      "correct=female   guess=male     name=Imojean                       \n",
      "correct=female   guess=male     name=Ines                          \n",
      "correct=female   guess=male     name=Ivory                         \n",
      "correct=female   guess=male     name=Jean                          \n",
      "correct=female   guess=male     name=Joannes                       \n",
      "correct=female   guess=male     name=Jorey                         \n",
      "correct=female   guess=male     name=Judy                          \n",
      "correct=female   guess=male     name=Lois                          \n",
      "correct=female   guess=male     name=Lorain                        \n",
      "correct=female   guess=male     name=Lust                          \n",
      "correct=female   guess=male     name=Maddy                         \n",
      "correct=female   guess=male     name=Marlo                         \n",
      "correct=female   guess=male     name=Max                           \n",
      "correct=female   guess=male     name=Mead                          \n",
      "correct=female   guess=male     name=Mercedes                      \n",
      "correct=female   guess=male     name=Mignon                        \n",
      "correct=female   guess=male     name=Milicent                      \n",
      "correct=female   guess=male     name=Miriam                        \n",
      "correct=female   guess=male     name=Monique                       \n",
      "correct=female   guess=male     name=Myriam                        \n",
      "correct=female   guess=male     name=Nan                           \n",
      "correct=female   guess=male     name=Norean                        \n",
      "correct=female   guess=male     name=Olive                         \n",
      "correct=female   guess=male     name=Polly                         \n",
      "correct=female   guess=male     name=Raquel                        \n",
      "correct=female   guess=male     name=Renel                         \n",
      "correct=female   guess=male     name=Riannon                       \n",
      "correct=female   guess=male     name=Robbyn                        \n",
      "correct=female   guess=male     name=Robin                         \n",
      "correct=female   guess=male     name=Rodie                         \n",
      "correct=female   guess=male     name=Rosalind                      \n",
      "correct=female   guess=male     name=Rosamund                      \n",
      "correct=female   guess=male     name=Rose                          \n",
      "correct=female   guess=male     name=Rowe                          \n",
      "correct=female   guess=male     name=Rozamond                      \n",
      "correct=female   guess=male     name=Rubie                         \n",
      "correct=female   guess=male     name=Ruthann                       \n",
      "correct=female   guess=male     name=Sal                           \n",
      "correct=female   guess=male     name=Sam                           \n",
      "correct=female   guess=male     name=Shel                          \n",
      "correct=female   guess=male     name=Sib                           \n",
      "correct=female   guess=male     name=Sileas                        \n",
      "correct=female   guess=male     name=Sophey                        \n",
      "correct=female   guess=male     name=Starlin                       \n",
      "correct=female   guess=male     name=Sydel                         \n",
      "correct=female   guess=male     name=Sydney                        \n",
      "correct=female   guess=male     name=Ted                           \n",
      "correct=female   guess=male     name=Tiffy                         \n",
      "correct=female   guess=male     name=Tracey                        \n",
      "correct=female   guess=male     name=Trudey                        \n",
      "correct=female   guess=male     name=Umeko                         \n",
      "correct=female   guess=male     name=Val                           \n",
      "correct=female   guess=male     name=Valery                        \n",
      "correct=female   guess=male     name=Wally                         \n",
      "correct=female   guess=male     name=Wren                          \n",
      "correct=female   guess=male     name=Yoko                          \n",
      "correct=male     guess=female   name=Anatole                       \n",
      "correct=male     guess=female   name=Anthony                       \n",
      "correct=male     guess=female   name=Antony                        \n",
      "correct=male     guess=female   name=Aubrey                        \n",
      "correct=male     guess=female   name=Avi                           \n",
      "correct=male     guess=female   name=Baily                         \n",
      "correct=male     guess=female   name=Beau                          \n",
      "correct=male     guess=female   name=Cain                          \n",
      "correct=male     guess=female   name=Cal                           \n",
      "correct=male     guess=female   name=Carey                         \n",
      "correct=male     guess=female   name=Carlin                        \n",
      "correct=male     guess=female   name=Chaunce                       \n",
      "correct=male     guess=female   name=Chauncey                      \n",
      "correct=male     guess=female   name=Clarance                      \n",
      "correct=male     guess=female   name=Cobby                         \n",
      "correct=male     guess=female   name=Cole                          \n",
      "correct=male     guess=female   name=Constantine                   \n",
      "correct=male     guess=female   name=Cornellis                     \n",
      "correct=male     guess=female   name=Dennis                        \n",
      "correct=male     guess=female   name=Duane                         \n",
      "correct=male     guess=female   name=Earle                         \n",
      "correct=male     guess=female   name=Elijah                        \n",
      "correct=male     guess=female   name=Erin                          \n",
      "correct=male     guess=female   name=Eustace                       \n",
      "correct=male     guess=female   name=Gabe                          \n",
      "correct=male     guess=female   name=Gabriele                      \n",
      "correct=male     guess=female   name=Gale                          \n",
      "correct=male     guess=female   name=Georgia                       \n",
      "correct=male     guess=female   name=Giovanni                      \n",
      "correct=male     guess=female   name=Hari                          \n",
      "correct=male     guess=female   name=Isa                           \n",
      "correct=male     guess=female   name=Isaiah                        \n",
      "correct=male     guess=female   name=Isidore                       \n",
      "correct=male     guess=female   name=Izzy                          \n",
      "correct=male     guess=female   name=Jamey                         \n",
      "correct=male     guess=female   name=Jere                          \n",
      "correct=male     guess=female   name=Jessee                        \n",
      "correct=male     guess=female   name=Jonny                         \n",
      "correct=male     guess=female   name=Kalil                         \n",
      "correct=male     guess=female   name=Kelly                         \n",
      "correct=male     guess=female   name=Kit                           \n",
      "correct=male     guess=female   name=Kris                          \n",
      "correct=male     guess=female   name=Lay                           \n",
      "correct=male     guess=female   name=Lesley                        \n",
      "correct=male     guess=female   name=Lindsay                       \n",
      "correct=male     guess=female   name=Lorne                         \n",
      "correct=male     guess=female   name=Maddie                        \n",
      "correct=male     guess=female   name=Martyn                        \n",
      "correct=male     guess=female   name=Maurice                       \n",
      "correct=male     guess=female   name=Maxie                         \n",
      "correct=male     guess=female   name=Maximilien                    \n",
      "correct=male     guess=female   name=Michele                       \n",
      "correct=male     guess=female   name=Micky                         \n",
      "correct=male     guess=female   name=Morly                         \n",
      "correct=male     guess=female   name=Nat                           \n",
      "correct=male     guess=female   name=Nichole                       \n",
      "correct=male     guess=female   name=Nicky                         \n",
      "correct=male     guess=female   name=Obie                          \n",
      "correct=male     guess=female   name=Pattie                        \n",
      "correct=male     guess=female   name=Phil                          \n",
      "correct=male     guess=female   name=Prince                        \n",
      "correct=male     guess=female   name=Ray                           \n",
      "correct=male     guess=female   name=Sayre                         \n",
      "correct=male     guess=female   name=Tabby                         \n",
      "correct=male     guess=female   name=Tate                          \n",
      "correct=male     guess=female   name=Teddie                        \n",
      "correct=male     guess=female   name=Tedie                         \n",
      "correct=male     guess=female   name=Tobie                         \n",
      "correct=male     guess=female   name=Vale                          \n",
      "correct=male     guess=female   name=Verne                         \n",
      "correct=male     guess=female   name=Zacherie                      \n"
     ]
    }
   ],
   "source": [
    "for (tag, guess, name) in sorted(errors):\n",
    "    print('correct={:<8} guess={:<8s} name={:<30}'.format(tag, guess, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking through this list of errors makes it clear that some suffixes that are more than one letter can be indicative of name genders. For example, names ending in yn appear to be predominantly female, despite the fact that names ending in n tend to be male; and names ending in ch are usually male, even though names that end in h tend to be female. We therefore adjust our feature extractor to include features for two-letter suffixes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'suffix1': word[-1:],'suffix2': word[-2:]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebuilding the classifier with the new feature extractor, we see that the performance on the dev-test dataset improves by almost 2 percentage points (from 76.5% to 78.2%):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error analysis procedure can then be repeated, checking for patterns in the errors that are made by the newly improved classifier. Each time the error analysis procedure is repeated, we should select a different dev-test/training split, to ensure that the classifier does not start to reflect idiosyncrasies in the dev-test set.\n",
    "\n",
    "But once we've used the dev-test set to help us develop the model, we can no longer trust that it will give us an accurate idea of how well the model would perform on new data. It is therefore important to keep the test set separate, and unused, until our model development is complete. At that point, we can use the test set to evaluate how well our model will perform on new input values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
